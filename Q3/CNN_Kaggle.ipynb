{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "IR6VdJQm4ery",
    "outputId": "98a2c2d5-ea2f-402c-8ac9-23d17083c840"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Change these paths according to your folder structure.\n",
    "'''\n",
    "train_data_path = \"./trainset\"\n",
    "test_data_path = \"./testset\"\n",
    "checkpoint_path = \"./checkpoints\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "zLJrZek0M2M4",
    "outputId": "5b90b5b3-79fd-4c94-ea77-71590112c6bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:160: UserWarning: pylab import has clobbered these variables: ['indices']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "class CatDogDataset(Dataset):\n",
    "    splits = ('train', 'train+unlabeled', 'unlabeled', 'test')\n",
    "\n",
    "    def __init__(self, root, split='train', transform=None, target_transform=None):\n",
    "        if split not in self.splits:\n",
    "            raise ValueError('Split \"{}\" not found. Valid splits are: {}'.format(\n",
    "                split, ', '.join(self.splits),\n",
    "            ))\n",
    "        self.root = os.path.expanduser(root)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.split = split  # train/test\n",
    "        self.classes = np.asarray(['Dog', 'Cat'])\n",
    "        self.labels = None\n",
    "        # now load the picked numpy arrays\n",
    "        if self.split == 'train':\n",
    "            self.paths = glob.glob(root + 'Dog/*')\n",
    "            self.paths.extend(glob.glob(root + 'Cat/*'))\n",
    "            self.labels = [(0 if self.paths[i][-7:-4]=='Dog' else 1) for i,path in enumerate(self.paths)]\n",
    "        elif self.split == 'test':\n",
    "            self.paths = [os.path.join(root, \"{}.jpg\".format(i)) for i in range(1, len(glob.glob(root + \"/*\")) + 1)]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        img = Image.open(self.paths[index]).convert('RGB')\n",
    "        \n",
    "        if self.labels is not None:\n",
    "            target = int(self.labels[index])\n",
    "        else:\n",
    "            target = torch.Tensor(0)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mHD0gZvCHwFs"
   },
   "outputs": [],
   "source": [
    "# Loading dataset\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# Hyper parameters\n",
    "batch_size = 32\n",
    "validationRatio = 0.1\n",
    "\n",
    "dataset = CatDogDataset(train_data_path, split='train', transform=transforms.ToTensor(), target_transform=None)\n",
    "\n",
    "indices = torch.randperm(len(dataset))\n",
    "train_indices = indices[:len(indices) - int((validationRatio) * len(dataset))]\n",
    "train_sampler = torch.utils.data.sampler.SubsetRandomSampler(train_indices)\n",
    "valid_indices = indices[len(indices) - int(validationRatio * len(dataset)):]\n",
    "valid_sampler = torch.utils.data.sampler.SubsetRandomSampler(valid_indices)\n",
    "\n",
    "# Dataset\n",
    "train_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           sampler = train_sampler,\n",
    "                                           shuffle=False)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           sampler = valid_sampler,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UKh8dj2Na2sN"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def save_checkpoint(acc, best_acc, checkpoints_path):\n",
    "  state_dict = {\n",
    "          'epoch': epoch + 1,\n",
    "          'model_dict': model.state_dict(),\n",
    "          'optim_dict': optimizer.state_dict()\n",
    "        }\n",
    "  torch.save(state_dict,\n",
    "         os.path.join(checkpoints_path,\n",
    "                      \"last.pth\".format(acc)))\n",
    "  if acc > best_acc:\n",
    "    if best_acc > 0:\n",
    "      os.remove(\n",
    "          os.path.join(\n",
    "              checkpoints_path,\n",
    "              \"best_{acc:.4f}.pth\".format(acc=best_acc)\n",
    "          )\n",
    "      )\n",
    "    best_acc = acc\n",
    "    torch.save(state_dict,\n",
    "               os.path.join(checkpoints_path,\n",
    "                            \"best_{acc:.4f}.pth\".format(acc=acc)))\n",
    "  return best_acc\n",
    "\n",
    "def load_checkpoint(model, checkpoint_path, optimizer=None, continue_from_epoch=True):\n",
    "    print(\"Loading checkpoint: {}\".format(checkpoint_path))\n",
    "    state = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(state['model_dict'])\n",
    "    if optimizer is not None:\n",
    "        optimizer.load_state_dict(state['optim_dict'])\n",
    "\n",
    "    epoch = 0\n",
    "    if continue_from_epoch:\n",
    "        epoch = state['epoch']\n",
    "    return epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uIHwPWjMiVqM"
   },
   "outputs": [],
   "source": [
    "from torch.optim import Optimizer\n",
    "from torch.optim.optimizer import required\n",
    "\n",
    "class SGDNesterov(Optimizer):\n",
    "  def __init__(self, params, lr=required, momentum=0.9):\n",
    "    defaults = dict(lr=lr, momentum=momentum)\n",
    "    super(SGDNesterov, self).__init__(params, defaults)\n",
    "\n",
    "  def __setstate__(self, state):\n",
    "    super(SGDNesterov, self).__setstate__(state)\n",
    "    for group in self.param_groups:\n",
    "        group.setdefault('nesterov', True)\n",
    "\n",
    "  def step(self):\n",
    "    loss = None\n",
    "\n",
    "    for group in self.param_groups:\n",
    "        momentum = group['momentum']\n",
    "\n",
    "        for p in group['params']:\n",
    "            if p.grad is None:\n",
    "                continue\n",
    "            d_p = p.grad.data\n",
    "            if momentum != 0:\n",
    "                param_state = self.state[p]\n",
    "                if 'momentum_buffer' not in param_state:\n",
    "                  buf = param_state['momentum_buffer'] = torch.zeros_like(p.data)\n",
    "                else:\n",
    "                  buf = param_state['momentum_buffer']\n",
    "                  \n",
    "                buf.mul_(momentum).add_(d_p)\n",
    "                d_p = d_p.add(momentum, buf)\n",
    "\n",
    "            p.data.add_(-group['lr'], d_p)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jqXsY-sbGqnL"
   },
   "outputs": [],
   "source": [
    "from torch.nn import Module\n",
    "from torch.nn import Parameter\n",
    "from torch.nn import init\n",
    "\n",
    "class BatchNorm(Module):\n",
    "  def __init__(self, num_features):\n",
    "      super(BatchNorm, self).__init__()\n",
    "      self.num_features = num_features\n",
    "      self.gamma = Parameter(torch.Tensor(num_features))\n",
    "      self.beta = Parameter(torch.Tensor(num_features))\n",
    "      self.reset()\n",
    "  \n",
    "  def reset(self):\n",
    "    init.uniform_(self.gamma)\n",
    "    init.zeros_(self.beta)\n",
    "\n",
    "  def forward(self, input):\n",
    "    mu = input.mean((0,2,3), keepdim=True)\n",
    "    variance = torch.mean((input - mu) ** 2, (0,2,3), keepdim=True)\n",
    "    input_norm = (input - mu) / torch.sqrt(variance + 1e-5)\n",
    "    out = self.gamma.view(1, self.num_features, 1, 1) * input_norm + self.beta.view(1, self.num_features, 1, 1)\n",
    "    return out\n",
    "\n",
    "  def extra_repr(self):\n",
    "      return 'num_features={}'.format(\n",
    "          self.num_features\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mO1IF0NnAEDz"
   },
   "outputs": [],
   "source": [
    "from torch.nn import Module\n",
    "from torch.nn import Parameter\n",
    "from torch.nn import init\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class Dropout(Module):\n",
    "  def __init__(self, p=0.5):\n",
    "      super(Dropout, self).__init__()\n",
    "      self.p = p\n",
    "\n",
    "  def forward(self, input):\n",
    "    if self.train():\n",
    "      prob = torch.ones(input.size()) * self.p\n",
    "      dropout = Variable(torch.bernoulli(prob)).to(\"cuda:0\")\n",
    "      output = input * dropout * (1/(1-self.p))\n",
    "    else:\n",
    "      output = input\n",
    "    \n",
    "    return output\n",
    "\n",
    "  def extra_repr(self):\n",
    "      return 'p={}'.format(\n",
    "          self.p\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mF5c4QgmQDIR"
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Convolutional neural network (two convolutional layers)\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, cfg, num_classes=10):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.cfg = cfg\n",
    "        self.features = self.make_layers()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(True),\n",
    "            Dropout(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(True),\n",
    "            Dropout(),\n",
    "            nn.Linear(1024, num_classes),\n",
    "        )\n",
    "        \n",
    "    def make_layers(self):\n",
    "      print(self.cfg)\n",
    "      layers = []\n",
    "      in_channels = 3\n",
    "      for v in self.cfg:\n",
    "          if v == 'M':\n",
    "              layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "          else:\n",
    "              conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "              layers += [conv2d, BatchNorm(v), nn.ReLU(inplace=True)]\n",
    "              in_channels = v\n",
    "      return nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "model = ConvNet([64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'], num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_for_prediction = \"./checkpoints/2019-02-13_02-42-55/best_88.0440.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 809
    },
    "colab_type": "code",
    "id": "dwgU5DcR-wOP",
    "outputId": "e6e9184a-0aba-470b-d8ae-7521266bcbc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint: ./checkpoints/2019-02-13_02-42-55/best_88.0440.pth\n",
      "Testing model: ConvNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm(num_features=64)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm(num_features=128)\n",
      "    (6): ReLU(inplace)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): BatchNorm(num_features=256)\n",
      "    (10): ReLU(inplace)\n",
      "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (12): BatchNorm(num_features=256)\n",
      "    (13): ReLU(inplace)\n",
      "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (16): BatchNorm(num_features=512)\n",
      "    (17): ReLU(inplace)\n",
      "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (19): BatchNorm(num_features=512)\n",
      "    (20): ReLU(inplace)\n",
      "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (23): BatchNorm(num_features=512)\n",
      "    (24): ReLU(inplace)\n",
      "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (26): BatchNorm(num_features=512)\n",
      "    (27): ReLU(inplace)\n",
      "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=1024, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x000001628CC9D080>\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This cell is for producing a prediction csv file on the test dataset.\n",
    "Run all the cells before this one first.\n",
    "'''\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "\n",
    "def testModel(test_dir, local_model):\n",
    "    local_model.eval()\n",
    "    print ('Testing model: {}'.format(str(local_model)))\n",
    "\n",
    "    test_set = CatDogDataset(test_dir, split='test', transform=transforms.ToTensor(), target_transform=None)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_set,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=False)\n",
    "    print(test_loader)\n",
    "\n",
    "    predictions = []\n",
    "    for i, (images, _) in enumerate(test_loader):\n",
    "        images = images.to(device)\n",
    "        # compute y_pred\n",
    "        y_pred = model(images).data.max(1)[1].cpu().numpy()\n",
    "        predictions.extend(test_set.classes[y_pred])\n",
    "\n",
    "    return predictions\n",
    "\n",
    "def predictions_to_csv(predictions, csv_path):\n",
    "    fd = pd.DataFrame({\"label\": predictions})\n",
    "    fd.index = np.arange(1, len(predictions) + 1)\n",
    "    fd.to_csv(csv_path, index_label=\"id\")\n",
    "\n",
    "# Making prediction and saving\n",
    "\n",
    "load_checkpoint(model, checkpoint_for_prediction)\n",
    "predictions = testModel(test_data_path, model)\n",
    "csv_path = './submission.csv'\n",
    "predictions_to_csv(predictions, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4762
    },
    "colab_type": "code",
    "id": "2ZvGp6wMnumz",
    "outputId": "7240e65a-616a-4e99-8f27-ccd4b0115f3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\n",
      "Epoch [1/50]\n",
      "Step [100/563], Loss: 0.6515(0.6764), Acc: 71.875(57.219)\n",
      "Step [200/563], Loss: 0.5424(0.6495), Acc: 75.000(61.672)\n",
      "Step [300/563], Loss: 0.4069(0.6226), Acc: 81.250(64.844)\n",
      "Step [400/563], Loss: 0.5289(0.6092), Acc: 68.750(66.297)\n",
      "Step [500/563], Loss: 0.8072(0.5908), Acc: 59.375(67.950)\n",
      "Validation Accuracy : 75.1376 %, Loss : 0.5130\n",
      "Epoch [2/50]\n",
      "Step [100/563], Loss: 0.4069(0.4798), Acc: 71.875(77.688)\n",
      "Step [200/563], Loss: 0.2949(0.4658), Acc: 90.625(78.234)\n",
      "Step [300/563], Loss: 0.7697(0.4563), Acc: 65.625(78.688)\n",
      "Step [400/563], Loss: 0.6086(0.4491), Acc: 59.375(78.969)\n",
      "Step [500/563], Loss: 0.3217(0.4424), Acc: 90.625(79.394)\n",
      "Validation Accuracy : 78.3892 %, Loss : 0.4437\n",
      "Epoch [3/50]\n",
      "Step [100/563], Loss: 0.4143(0.3472), Acc: 84.375(84.875)\n",
      "Step [200/563], Loss: 0.4055(0.3559), Acc: 81.250(84.469)\n",
      "Step [300/563], Loss: 0.4742(0.3499), Acc: 87.500(84.927)\n",
      "Step [400/563], Loss: 0.3274(0.3478), Acc: 84.375(84.992)\n",
      "Step [500/563], Loss: 0.3614(0.3463), Acc: 84.375(85.037)\n",
      "Validation Accuracy : 83.6918 %, Loss : 0.3866\n",
      "Epoch [4/50]\n",
      "Step [100/563], Loss: 0.1545(0.2806), Acc: 93.750(88.875)\n",
      "Step [200/563], Loss: 0.4114(0.2826), Acc: 78.125(88.281)\n",
      "Step [300/563], Loss: 0.2052(0.2840), Acc: 90.625(88.073)\n",
      "Step [400/563], Loss: 0.1225(0.2838), Acc: 96.875(87.953)\n",
      "Step [500/563], Loss: 0.2628(0.2795), Acc: 90.625(88.206)\n",
      "Validation Accuracy : 83.6918 %, Loss : 0.3762\n",
      "Epoch [5/50]\n",
      "Step [100/563], Loss: 0.2295(0.1958), Acc: 90.625(91.938)\n",
      "Step [200/563], Loss: 0.0675(0.2118), Acc: 100.000(91.266)\n",
      "Step [300/563], Loss: 0.2623(0.2174), Acc: 87.500(90.990)\n",
      "Step [400/563], Loss: 0.2363(0.2210), Acc: 87.500(90.805)\n",
      "Step [500/563], Loss: 0.1797(0.2214), Acc: 93.750(90.819)\n",
      "Validation Accuracy : 84.7924 %, Loss : 0.3762\n",
      "Epoch [6/50]\n",
      "Step [100/563], Loss: 0.2616(0.1651), Acc: 87.500(93.656)\n",
      "Step [200/563], Loss: 0.0865(0.1668), Acc: 100.000(93.562)\n",
      "Step [300/563], Loss: 0.1244(0.1713), Acc: 96.875(93.312)\n",
      "Step [400/563], Loss: 0.0886(0.1742), Acc: 96.875(93.148)\n",
      "Step [500/563], Loss: 0.1579(0.1741), Acc: 87.500(93.056)\n",
      "Validation Accuracy : 85.3927 %, Loss : 0.3718\n",
      "Epoch [7/50]\n",
      "Step [100/563], Loss: 0.0361(0.1054), Acc: 100.000(96.406)\n",
      "Step [200/563], Loss: 0.2593(0.1155), Acc: 87.500(95.719)\n",
      "Step [300/563], Loss: 0.0530(0.1225), Acc: 100.000(95.271)\n",
      "Step [400/563], Loss: 0.1743(0.1261), Acc: 93.750(95.070)\n",
      "Step [500/563], Loss: 0.0616(0.1319), Acc: 96.875(94.856)\n",
      "Validation Accuracy : 85.1926 %, Loss : 0.4441\n",
      "Epoch [8/50]\n",
      "Step [100/563], Loss: 0.3789(0.0850), Acc: 81.250(96.906)\n",
      "Step [200/563], Loss: 0.0695(0.0765), Acc: 96.875(97.328)\n",
      "Step [300/563], Loss: 0.0321(0.0849), Acc: 100.000(96.906)\n",
      "Step [400/563], Loss: 0.1089(0.0938), Acc: 96.875(96.414)\n",
      "Step [500/563], Loss: 0.1065(0.0974), Acc: 93.750(96.338)\n",
      "Validation Accuracy : 83.5918 %, Loss : 0.4720\n",
      "Epoch [9/50]\n",
      "Step [100/563], Loss: 0.1651(0.0858), Acc: 90.625(96.812)\n",
      "Step [200/563], Loss: 0.0725(0.0845), Acc: 96.875(96.938)\n",
      "Step [300/563], Loss: 0.0398(0.0825), Acc: 100.000(96.958)\n",
      "Step [400/563], Loss: 0.0251(0.0840), Acc: 100.000(96.953)\n",
      "Step [500/563], Loss: 0.0731(0.0840), Acc: 96.875(96.856)\n",
      "Validation Accuracy : 85.5428 %, Loss : 0.4558\n",
      "Epoch [10/50]\n",
      "Step [100/563], Loss: 0.0969(0.0469), Acc: 93.750(98.375)\n",
      "Step [200/563], Loss: 0.0553(0.0547), Acc: 100.000(98.062)\n",
      "Step [300/563], Loss: 0.0201(0.0525), Acc: 100.000(98.135)\n",
      "Step [400/563], Loss: 0.2117(0.0599), Acc: 90.625(97.781)\n",
      "Step [500/563], Loss: 0.0742(0.0651), Acc: 93.750(97.550)\n",
      "Validation Accuracy : 86.2431 %, Loss : 0.4500\n",
      "Epoch [11/50]\n",
      "Step [100/563], Loss: 0.0063(0.0471), Acc: 100.000(98.219)\n",
      "Step [200/563], Loss: 0.0511(0.0397), Acc: 96.875(98.547)\n",
      "Step [300/563], Loss: 0.1694(0.0480), Acc: 90.625(98.208)\n",
      "Step [400/563], Loss: 0.0405(0.0533), Acc: 96.875(97.953)\n",
      "Step [500/563], Loss: 0.0606(0.0535), Acc: 93.750(97.975)\n",
      "Validation Accuracy : 85.7429 %, Loss : 0.5127\n",
      "Epoch [12/50]\n",
      "Step [100/563], Loss: 0.0250(0.0327), Acc: 100.000(98.969)\n",
      "Step [200/563], Loss: 0.1634(0.0297), Acc: 90.625(99.031)\n",
      "Step [300/563], Loss: 0.1215(0.0422), Acc: 93.750(98.531)\n",
      "Step [400/563], Loss: 0.0438(0.0481), Acc: 96.875(98.258)\n",
      "Step [500/563], Loss: 0.1478(0.0490), Acc: 93.750(98.231)\n",
      "Validation Accuracy : 85.2426 %, Loss : 0.4990\n",
      "Epoch [13/50]\n",
      "Step [100/563], Loss: 0.0057(0.0349), Acc: 100.000(98.531)\n",
      "Step [200/563], Loss: 0.0350(0.0351), Acc: 100.000(98.609)\n",
      "Step [300/563], Loss: 0.0256(0.0347), Acc: 100.000(98.604)\n",
      "Step [400/563], Loss: 0.0245(0.0346), Acc: 100.000(98.648)\n",
      "Step [500/563], Loss: 0.0030(0.0360), Acc: 100.000(98.638)\n",
      "Validation Accuracy : 85.3427 %, Loss : 0.5411\n",
      "Epoch [14/50]\n",
      "Step [100/563], Loss: 0.0415(0.0309), Acc: 96.875(98.906)\n",
      "Step [200/563], Loss: 0.0420(0.0247), Acc: 96.875(99.125)\n",
      "Step [300/563], Loss: 0.0014(0.0263), Acc: 100.000(99.094)\n",
      "Step [400/563], Loss: 0.0130(0.0299), Acc: 100.000(98.961)\n",
      "Step [500/563], Loss: 0.0014(0.0335), Acc: 100.000(98.831)\n",
      "Validation Accuracy : 84.9925 %, Loss : 0.5930\n",
      "Epoch [15/50]\n",
      "Step [100/563], Loss: 0.0399(0.0228), Acc: 96.875(99.062)\n",
      "Step [200/563], Loss: 0.0793(0.0245), Acc: 96.875(99.047)\n",
      "Step [300/563], Loss: 0.0048(0.0270), Acc: 100.000(99.000)\n",
      "Step [400/563], Loss: 0.2197(0.0275), Acc: 96.875(99.000)\n",
      "Step [500/563], Loss: 0.0615(0.0273), Acc: 96.875(98.963)\n",
      "Validation Accuracy : 85.5928 %, Loss : 0.5642\n",
      "Epoch [16/50]\n",
      "Step [100/563], Loss: 0.0742(0.0293), Acc: 96.875(98.938)\n",
      "Step [200/563], Loss: 0.0085(0.0243), Acc: 100.000(99.125)\n",
      "Step [300/563], Loss: 0.0029(0.0227), Acc: 100.000(99.250)\n",
      "Step [400/563], Loss: 0.0317(0.0259), Acc: 96.875(99.109)\n",
      "Step [500/563], Loss: 0.0676(0.0272), Acc: 96.875(98.994)\n",
      "Validation Accuracy : 84.9425 %, Loss : 0.6397\n",
      "Epoch [17/50]\n",
      "Step [100/563], Loss: 0.0015(0.0254), Acc: 100.000(99.156)\n",
      "Step [200/563], Loss: 0.0067(0.0206), Acc: 100.000(99.312)\n",
      "Step [300/563], Loss: 0.0150(0.0177), Acc: 100.000(99.427)\n",
      "Step [400/563], Loss: 0.0034(0.0205), Acc: 100.000(99.328)\n",
      "Step [500/563], Loss: 0.0007(0.0219), Acc: 100.000(99.225)\n",
      "Validation Accuracy : 84.8924 %, Loss : 0.6359\n",
      "Epoch [18/50]\n",
      "Step [100/563], Loss: 0.0027(0.0176), Acc: 100.000(99.375)\n",
      "Step [200/563], Loss: 0.0033(0.0179), Acc: 100.000(99.375)\n",
      "Step [300/563], Loss: 0.0039(0.0202), Acc: 100.000(99.281)\n",
      "Step [400/563], Loss: 0.0011(0.0207), Acc: 100.000(99.273)\n",
      "Step [500/563], Loss: 0.0029(0.0202), Acc: 100.000(99.300)\n",
      "Validation Accuracy : 86.9935 %, Loss : 0.6209\n",
      "Epoch [19/50]\n",
      "Step [100/563], Loss: 0.0022(0.0137), Acc: 100.000(99.562)\n",
      "Step [200/563], Loss: 0.0021(0.0133), Acc: 100.000(99.562)\n",
      "Step [300/563], Loss: 0.0234(0.0117), Acc: 100.000(99.635)\n",
      "Step [400/563], Loss: 0.0156(0.0149), Acc: 100.000(99.500)\n",
      "Step [500/563], Loss: 0.0022(0.0172), Acc: 100.000(99.406)\n",
      "Validation Accuracy : 84.8924 %, Loss : 0.6623\n",
      "Epoch [20/50]\n",
      "Step [100/563], Loss: 0.0024(0.0295), Acc: 100.000(99.000)\n",
      "Step [200/563], Loss: 0.0016(0.0208), Acc: 100.000(99.297)\n",
      "Step [300/563], Loss: 0.0109(0.0172), Acc: 100.000(99.406)\n",
      "Step [400/563], Loss: 0.0074(0.0163), Acc: 100.000(99.453)\n",
      "Step [500/563], Loss: 0.0007(0.0156), Acc: 100.000(99.475)\n",
      "Validation Accuracy : 86.7934 %, Loss : 0.6108\n",
      "Epoch [21/50]\n",
      "Step [100/563], Loss: 0.0968(0.0177), Acc: 96.875(99.312)\n",
      "Step [200/563], Loss: 0.0003(0.0148), Acc: 100.000(99.469)\n",
      "Step [300/563], Loss: 0.0071(0.0123), Acc: 100.000(99.583)\n",
      "Step [400/563], Loss: 0.0941(0.0133), Acc: 96.875(99.539)\n",
      "Step [500/563], Loss: 0.1813(0.0144), Acc: 90.625(99.500)\n",
      "Validation Accuracy : 86.1431 %, Loss : 0.6387\n",
      "Epoch [22/50]\n",
      "Step [100/563], Loss: 0.0010(0.0074), Acc: 100.000(99.781)\n",
      "Step [200/563], Loss: 0.0012(0.0078), Acc: 100.000(99.734)\n",
      "Step [300/563], Loss: 0.0038(0.0069), Acc: 100.000(99.781)\n",
      "Step [400/563], Loss: 0.0026(0.0093), Acc: 100.000(99.688)\n",
      "Step [500/563], Loss: 0.0028(0.0104), Acc: 100.000(99.656)\n",
      "Validation Accuracy : 86.0930 %, Loss : 0.6549\n",
      "Epoch [23/50]\n",
      "Step [100/563], Loss: 0.0011(0.0311), Acc: 100.000(98.719)\n",
      "Step [200/563], Loss: 0.0002(0.0189), Acc: 100.000(99.219)\n",
      "Step [300/563], Loss: 0.0002(0.0159), Acc: 100.000(99.344)\n",
      "Step [400/563], Loss: 0.0343(0.0159), Acc: 96.875(99.359)\n",
      "Step [500/563], Loss: 0.0116(0.0163), Acc: 100.000(99.362)\n",
      "Validation Accuracy : 86.0430 %, Loss : 0.6189\n",
      "Epoch [24/50]\n",
      "Step [100/563], Loss: 0.0018(0.0095), Acc: 100.000(99.656)\n",
      "Step [200/563], Loss: 0.0002(0.0085), Acc: 100.000(99.719)\n",
      "Step [300/563], Loss: 0.0029(0.0076), Acc: 100.000(99.750)\n",
      "Step [400/563], Loss: 0.0011(0.0072), Acc: 100.000(99.766)\n",
      "Step [500/563], Loss: 0.0373(0.0063), Acc: 96.875(99.787)\n",
      "Validation Accuracy : 87.4437 %, Loss : 0.6330\n",
      "Epoch [25/50]\n",
      "Step [100/563], Loss: 0.0107(0.0090), Acc: 100.000(99.594)\n",
      "Step [200/563], Loss: 0.0399(0.0111), Acc: 96.875(99.531)\n",
      "Step [300/563], Loss: 0.0003(0.0114), Acc: 100.000(99.552)\n",
      "Step [400/563], Loss: 0.0002(0.0129), Acc: 100.000(99.516)\n",
      "Step [500/563], Loss: 0.0017(0.0114), Acc: 100.000(99.581)\n",
      "Validation Accuracy : 86.8934 %, Loss : 0.6840\n",
      "Epoch [26/50]\n",
      "Step [100/563], Loss: 0.0479(0.0118), Acc: 96.875(99.531)\n",
      "Step [200/563], Loss: 0.0013(0.0141), Acc: 100.000(99.406)\n",
      "Step [300/563], Loss: 0.0984(0.0156), Acc: 93.750(99.406)\n",
      "Step [400/563], Loss: 0.0039(0.0143), Acc: 100.000(99.461)\n",
      "Step [500/563], Loss: 0.0039(0.0137), Acc: 100.000(99.469)\n",
      "Validation Accuracy : 85.8929 %, Loss : 0.6716\n",
      "Epoch [27/50]\n",
      "Step [100/563], Loss: 0.0014(0.0120), Acc: 100.000(99.531)\n",
      "Step [200/563], Loss: 0.0015(0.0144), Acc: 100.000(99.453)\n",
      "Step [300/563], Loss: 0.0015(0.0146), Acc: 100.000(99.448)\n",
      "Step [400/563], Loss: 0.0006(0.0160), Acc: 100.000(99.414)\n",
      "Step [500/563], Loss: 0.0755(0.0172), Acc: 96.875(99.381)\n",
      "Validation Accuracy : 86.1431 %, Loss : 0.6379\n",
      "Epoch [28/50]\n",
      "Step [100/563], Loss: 0.0051(0.0106), Acc: 100.000(99.562)\n",
      "Step [200/563], Loss: 0.0066(0.0077), Acc: 100.000(99.719)\n",
      "Step [300/563], Loss: 0.0011(0.0065), Acc: 100.000(99.781)\n",
      "Step [400/563], Loss: 0.0057(0.0094), Acc: 100.000(99.680)\n",
      "Step [500/563], Loss: 0.0005(0.0097), Acc: 100.000(99.669)\n",
      "Validation Accuracy : 86.6433 %, Loss : 0.6625\n",
      "Epoch [29/50]\n",
      "Step [100/563], Loss: 0.0001(0.0062), Acc: 100.000(99.812)\n",
      "Step [200/563], Loss: 0.0001(0.0051), Acc: 100.000(99.859)\n",
      "Step [300/563], Loss: 0.0110(0.0048), Acc: 100.000(99.865)\n",
      "Step [400/563], Loss: 0.0152(0.0061), Acc: 100.000(99.820)\n",
      "Step [500/563], Loss: 0.0140(0.0072), Acc: 100.000(99.750)\n",
      "Validation Accuracy : 85.8929 %, Loss : 0.7566\n",
      "Epoch [30/50]\n",
      "Step [100/563], Loss: 0.0005(0.0032), Acc: 100.000(99.875)\n",
      "Step [200/563], Loss: 0.0002(0.0029), Acc: 100.000(99.891)\n",
      "Step [300/563], Loss: 0.0002(0.0036), Acc: 100.000(99.875)\n",
      "Step [400/563], Loss: 0.0023(0.0057), Acc: 100.000(99.805)\n",
      "Step [500/563], Loss: 0.0015(0.0062), Acc: 100.000(99.806)\n",
      "Validation Accuracy : 86.9935 %, Loss : 0.7147\n",
      "Epoch [31/50]\n",
      "Step [100/563], Loss: 0.1468(0.0095), Acc: 96.875(99.625)\n",
      "Step [200/563], Loss: 0.0001(0.0080), Acc: 100.000(99.672)\n",
      "Step [300/563], Loss: 0.0012(0.0077), Acc: 100.000(99.719)\n",
      "Step [400/563], Loss: 0.1153(0.0134), Acc: 93.750(99.492)\n",
      "Step [500/563], Loss: 0.0005(0.0131), Acc: 100.000(99.513)\n",
      "Validation Accuracy : 88.0440 %, Loss : 0.6178\n",
      "Epoch [32/50]\n",
      "Step [100/563], Loss: 0.0002(0.0062), Acc: 100.000(99.844)\n",
      "Step [200/563], Loss: 0.0004(0.0041), Acc: 100.000(99.906)\n",
      "Step [300/563], Loss: 0.0005(0.0032), Acc: 100.000(99.927)\n",
      "Step [400/563], Loss: 0.0002(0.0032), Acc: 100.000(99.906)\n",
      "Step [500/563], Loss: 0.0004(0.0032), Acc: 100.000(99.900)\n",
      "Validation Accuracy : 87.9440 %, Loss : 0.6588\n",
      "Epoch [33/50]\n",
      "Step [100/563], Loss: 0.0003(0.0004), Acc: 100.000(100.000)\n",
      "Step [200/563], Loss: 0.0001(0.0010), Acc: 100.000(99.969)\n",
      "Step [300/563], Loss: 0.0001(0.0008), Acc: 100.000(99.979)\n",
      "Step [400/563], Loss: 0.0002(0.0008), Acc: 100.000(99.977)\n",
      "Step [500/563], Loss: 0.0001(0.0011), Acc: 100.000(99.956)\n",
      "Validation Accuracy : 87.8439 %, Loss : 0.7255\n",
      "Epoch [34/50]\n",
      "Step [100/563], Loss: 0.0016(0.0040), Acc: 100.000(99.812)\n",
      "Step [200/563], Loss: 0.0002(0.0027), Acc: 100.000(99.906)\n",
      "Step [300/563], Loss: 0.0000(0.0021), Acc: 100.000(99.917)\n",
      "Step [400/563], Loss: 0.0000(0.0019), Acc: 100.000(99.922)\n",
      "Step [500/563], Loss: 0.0001(0.0017), Acc: 100.000(99.931)\n",
      "Validation Accuracy : 87.9940 %, Loss : 0.7219\n",
      "Epoch [35/50]\n",
      "Step [100/563], Loss: 0.0002(0.0012), Acc: 100.000(99.969)\n",
      "Step [200/563], Loss: 0.0001(0.0009), Acc: 100.000(99.984)\n",
      "Step [300/563], Loss: 0.0000(0.0011), Acc: 100.000(99.969)\n",
      "Step [400/563], Loss: 0.0003(0.0011), Acc: 100.000(99.961)\n",
      "Step [500/563], Loss: 0.0000(0.0011), Acc: 100.000(99.956)\n",
      "Validation Accuracy : 87.4937 %, Loss : 0.7646\n",
      "Epoch [36/50]\n",
      "Step [100/563], Loss: 0.0004(0.0006), Acc: 100.000(99.969)\n",
      "Step [200/563], Loss: 0.0000(0.0007), Acc: 100.000(99.984)\n",
      "Step [300/563], Loss: 0.0003(0.0031), Acc: 100.000(99.927)\n",
      "Step [400/563], Loss: 0.0268(0.0035), Acc: 96.875(99.891)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-d297b76ebb8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "This cell is for training the model and saving checkpoints\n",
    "'''\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Hyper parameters\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = SGDNesterov(model.parameters(), lr=learning_rate, momentum=0.9)#torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 5 epochs\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# Train the model\n",
    "trainLoss = []\n",
    "validLoss = []\n",
    "validAcc = []\n",
    "\n",
    "total_step = len(train_loader)\n",
    "trainAcc = []\n",
    "best_acc = 0\n",
    "datetime_str = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "checkpoints_saving_path = os.path.join(checkpoint_path, datetime_str)\n",
    "os.makedirs(checkpoints_path, exist_ok=True)\n",
    "for epoch in range(num_epochs):\n",
    "#     exp_lr_scheduler.step()\n",
    "    print('Epoch [{}/{}]'.format(epoch+1, num_epochs))\n",
    "    meanLoss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct_this_batch = (predicted == labels).sum().item()\n",
    "        correct += correct_this_batch\n",
    "        loss = criterion(outputs, labels)\n",
    "        meanLoss += loss.item()\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Step [{}/{}], Loss: {:.4f}({:.4f}), Acc: {:.3f}({:.3f})' \n",
    "                   .format(i+1, total_step, loss.item(), meanLoss / (i+1), correct_this_batch * 100 / labels.size(0), correct * 100 / total, )) \n",
    "        trainLoss.append(meanLoss/(i+1))\n",
    "        trainAcc.append(100*correct / total)\n",
    "    \n",
    "    \n",
    "    # valid the model\n",
    "    model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        meanLoss = 0\n",
    "        for images, labels in valid_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            meanLoss += loss.cpu().detach().numpy()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        acc  = 100 * correct / total\n",
    "        print('Validation Accuracy : {:.4f} %, Loss : {:.4f}'.format(100 * correct / total, meanLoss/len(valid_loader)))\n",
    "        validLoss.append(meanLoss/len(valid_loader))\n",
    "        validAcc.append(acc)\n",
    "        best_acc = save_checkpoint(acc, best_acc, checkpoints_path)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN - Kaggle",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
