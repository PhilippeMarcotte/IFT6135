{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "IR6VdJQm4ery",
    "outputId": "98a2c2d5-ea2f-402c-8ac9-23d17083c840"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Change these paths according to your folder structure.\n",
    "'''\n",
    "train_data_path = \"./trainset\"\n",
    "test_data_path = \"./testset\"\n",
    "checkpoint_path = \"./checkpoints\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "zLJrZek0M2M4",
    "outputId": "5b90b5b3-79fd-4c94-ea77-71590112c6bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "class CatDogDataset(Dataset):\n",
    "    splits = ('train', 'train+unlabeled', 'unlabeled', 'test')\n",
    "\n",
    "    def __init__(self, root, split='train', transform=None, target_transform=None):\n",
    "        if split not in self.splits:\n",
    "            raise ValueError('Split \"{}\" not found. Valid splits are: {}'.format(\n",
    "                split, ', '.join(self.splits),\n",
    "            ))\n",
    "        self.root = os.path.expanduser(root)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.split = split  # train/test\n",
    "        self.classes = np.asarray(['Dog', 'Cat'])\n",
    "        self.labels = None\n",
    "        if self.split == 'train':\n",
    "            self.paths = glob.glob(os.path.join(root, 'Dog', \"/*.jpg\"))\n",
    "            self.paths.extend(glob.glob(os.path.join(self.root, 'Cat', \"/*.jpg\")))\n",
    "            self.labels = [(0 if self.paths[i][-7:-4]=='Dog' else 1) for i,path in enumerate(self.paths)]\n",
    "        elif self.split == 'test':\n",
    "            self.paths = [os.path.join(root, \"{}.jpg\".format(i)) for i in range(1, len(glob.glob(root + \"/*\")) + 1)]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        img = Image.open(self.paths[index]).convert('RGB')\n",
    "        \n",
    "        if self.labels is not None:\n",
    "            target = int(self.labels[index])\n",
    "        else:\n",
    "            target = torch.Tensor(0)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mHD0gZvCHwFs"
   },
   "outputs": [],
   "source": [
    "# Loading dataset\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper parameters\n",
    "batch_size = 32\n",
    "validationRatio = 0.1\n",
    "\n",
    "dataset = CatDogDataset(train_data_path, split='train', transform=transforms.ToTensor(), target_transform=None)\n",
    "\n",
    "indices = torch.randperm(len(dataset))\n",
    "train_indices = indices[:len(indices) - int((validationRatio) * len(dataset))]\n",
    "train_sampler = torch.utils.data.sampler.SubsetRandomSampler(train_indices)\n",
    "valid_indices = indices[len(indices) - int(validationRatio * len(dataset)):]\n",
    "valid_sampler = torch.utils.data.sampler.SubsetRandomSampler(valid_indices)\n",
    "\n",
    "# Dataset\n",
    "train_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           sampler = train_sampler,\n",
    "                                           shuffle=False)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           sampler = valid_sampler,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UKh8dj2Na2sN"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def save_checkpoint(acc, best_acc, checkpoints_path):\n",
    "  state_dict = {\n",
    "          'epoch': epoch + 1,\n",
    "          'model_dict': model.state_dict(),\n",
    "          'optim_dict': optimizer.state_dict()\n",
    "        }\n",
    "  torch.save(state_dict,\n",
    "         os.path.join(checkpoints_path,\n",
    "                      \"last.pth\".format(acc)))\n",
    "  if acc > best_acc:\n",
    "    if best_acc > 0:\n",
    "      os.remove(\n",
    "          os.path.join(\n",
    "              checkpoints_path,\n",
    "              \"best_{acc:.4f}.pth\".format(acc=best_acc)\n",
    "          )\n",
    "      )\n",
    "    best_acc = acc\n",
    "    torch.save(state_dict,\n",
    "               os.path.join(checkpoints_path,\n",
    "                            \"best_{acc:.4f}.pth\".format(acc=acc)))\n",
    "  return best_acc\n",
    "\n",
    "def load_checkpoint(model, checkpoint_path, optimizer=None, continue_from_epoch=True):\n",
    "    print(\"Loading checkpoint: {}\".format(checkpoint_path))\n",
    "    state = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(state['model_dict'])\n",
    "    if optimizer is not None:\n",
    "        optimizer.load_state_dict(state['optim_dict'])\n",
    "\n",
    "    epoch = 0\n",
    "    if continue_from_epoch:\n",
    "        epoch = state['epoch']\n",
    "    return epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uIHwPWjMiVqM"
   },
   "outputs": [],
   "source": [
    "from torch.optim import Optimizer\n",
    "from torch.optim.optimizer import required\n",
    "\n",
    "class SGDNesterov(Optimizer):\n",
    "  def __init__(self, params, lr=required, momentum=0.9):\n",
    "    defaults = dict(lr=lr, momentum=momentum)\n",
    "    super(SGDNesterov, self).__init__(params, defaults)\n",
    "\n",
    "  def __setstate__(self, state):\n",
    "    super(SGDNesterov, self).__setstate__(state)\n",
    "    for group in self.param_groups:\n",
    "        group.setdefault('nesterov', True)\n",
    "\n",
    "  def step(self):\n",
    "    loss = None\n",
    "\n",
    "    for group in self.param_groups:\n",
    "        momentum = group['momentum']\n",
    "\n",
    "        for p in group['params']:\n",
    "            if p.grad is None:\n",
    "                continue\n",
    "            d_p = p.grad.data\n",
    "            if momentum != 0:\n",
    "                param_state = self.state[p]\n",
    "                if 'momentum_buffer' not in param_state:\n",
    "                  buf = param_state['momentum_buffer'] = torch.zeros_like(p.data)\n",
    "                else:\n",
    "                  buf = param_state['momentum_buffer']\n",
    "                  \n",
    "                buf.mul_(momentum).add_(d_p)\n",
    "                d_p = d_p.add(momentum, buf)\n",
    "\n",
    "            p.data.add_(-group['lr'], d_p)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jqXsY-sbGqnL"
   },
   "outputs": [],
   "source": [
    "from torch.nn import Module\n",
    "from torch.nn import Parameter\n",
    "from torch.nn import init\n",
    "\n",
    "class BatchNorm(Module):\n",
    "  def __init__(self, num_features):\n",
    "      super(BatchNorm, self).__init__()\n",
    "      self.num_features = num_features\n",
    "      self.gamma = Parameter(torch.Tensor(num_features))\n",
    "      self.beta = Parameter(torch.Tensor(num_features))\n",
    "      self.reset()\n",
    "  \n",
    "  def reset(self):\n",
    "    init.uniform_(self.gamma)\n",
    "    init.zeros_(self.beta)\n",
    "\n",
    "  def forward(self, input):\n",
    "    mu = input.mean((0,2,3), keepdim=True)\n",
    "    variance = torch.mean((input - mu) ** 2, (0,2,3), keepdim=True)\n",
    "    input_norm = (input - mu) / torch.sqrt(variance + 1e-5)\n",
    "    out = self.gamma.view(1, self.num_features, 1, 1) * input_norm + self.beta.view(1, self.num_features, 1, 1)\n",
    "    return out\n",
    "\n",
    "  def extra_repr(self):\n",
    "      return 'num_features={}'.format(\n",
    "          self.num_features\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mO1IF0NnAEDz"
   },
   "outputs": [],
   "source": [
    "from torch.nn import Module\n",
    "from torch.nn import Parameter\n",
    "from torch.nn import init\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class Dropout(Module):\n",
    "  def __init__(self, p=0.5):\n",
    "      super(Dropout, self).__init__()\n",
    "      self.p = p\n",
    "\n",
    "  def forward(self, input):\n",
    "    if self.train():\n",
    "      prob = torch.ones(input.size()) * self.p\n",
    "      dropout = Variable(torch.bernoulli(prob)).to(\"cuda:0\")\n",
    "      output = input * dropout * (1/(1-self.p))\n",
    "    else:\n",
    "      output = input\n",
    "    \n",
    "    return output\n",
    "\n",
    "  def extra_repr(self):\n",
    "      return 'p={}'.format(\n",
    "          self.p\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mF5c4QgmQDIR"
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Convolutional neural network (two convolutional layers)\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, cfg, num_classes=2):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.cfg = cfg\n",
    "        self.features = self.make_layers()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2048, 4096),\n",
    "            nn.ReLU(True),\n",
    "            Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            Dropout(),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        \n",
    "    def make_layers(self):\n",
    "      print(self.cfg)\n",
    "      layers = []\n",
    "      in_channels = 3\n",
    "      for v in self.cfg:\n",
    "          if v == 'M':\n",
    "              layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "          else:\n",
    "              conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "              layers += [conv2d, BatchNorm(v), nn.ReLU(inplace=True)]\n",
    "              in_channels = v\n",
    "      return nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "model = ConvNet([64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'], num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_for_prediction = \"./checkpoints/best_88.2941.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 809
    },
    "colab_type": "code",
    "id": "dwgU5DcR-wOP",
    "outputId": "e6e9184a-0aba-470b-d8ae-7521266bcbc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint: ./checkpoints/best_88.2941.pth\n",
      "Testing model: ConvNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm(num_features=64)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm(num_features=128)\n",
      "    (6): ReLU(inplace)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): BatchNorm(num_features=256)\n",
      "    (10): ReLU(inplace)\n",
      "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (12): BatchNorm(num_features=256)\n",
      "    (13): ReLU(inplace)\n",
      "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (16): BatchNorm(num_features=512)\n",
      "    (17): ReLU(inplace)\n",
      "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (19): BatchNorm(num_features=512)\n",
      "    (20): ReLU(inplace)\n",
      "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (23): BatchNorm(num_features=512)\n",
      "    (24): ReLU(inplace)\n",
      "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (26): BatchNorm(num_features=512)\n",
      "    (27): ReLU(inplace)\n",
      "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x000001628A0C6390>\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This cell is for producing a prediction csv file on the test dataset.\n",
    "Run all the cells before this one first.\n",
    "'''\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "\n",
    "def testModel(test_dir, local_model):\n",
    "    local_model.eval()\n",
    "    print ('Testing model: {}'.format(str(local_model)))\n",
    "\n",
    "    test_set = CatDogDataset(test_dir, split='test', transform=transforms.ToTensor(), target_transform=None)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_set,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=False)\n",
    "    print(test_loader)\n",
    "\n",
    "    predictions = []\n",
    "    for i, (images, _) in enumerate(test_loader):\n",
    "        images = images.to(device)\n",
    "        # compute y_pred\n",
    "        y_pred = model(images).data.max(1)[1].cpu().numpy()\n",
    "        predictions.extend(test_set.classes[y_pred])\n",
    "\n",
    "    return predictions\n",
    "\n",
    "def predictions_to_csv(predictions, csv_path):\n",
    "    fd = pd.DataFrame({\"label\": predictions})\n",
    "    fd.index = np.arange(1, len(predictions) + 1)\n",
    "    fd.to_csv(csv_path, index_label=\"id\")\n",
    "\n",
    "# Making prediction and saving\n",
    "\n",
    "load_checkpoint(model, checkpoint_for_prediction)\n",
    "predictions = testModel(test_data_path, model)\n",
    "csv_path = './submission.csv'\n",
    "predictions_to_csv(predictions, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4762
    },
    "colab_type": "code",
    "id": "2ZvGp6wMnumz",
    "outputId": "7240e65a-616a-4e99-8f27-ccd4b0115f3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50]\n",
      "Step [100/563], Loss: 0.0159(0.0248), Acc: 100.000(99.375)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-117-041c315be7ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    613\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# same-process loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 615\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    616\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    613\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# same-process loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 615\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    616\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-113-4b0dffbc2aa8>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[0mtuple\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mindex\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;32mclass\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \"\"\"\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpaths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RGB'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2608\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2609\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2610\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "This cell is for training the model and saving checkpoints\n",
    "'''\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Hyper parameters\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = SGDNesterov(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "# Train the model\n",
    "trainLoss = []\n",
    "validLoss = []\n",
    "validAcc = []\n",
    "\n",
    "total_step = len(train_loader)\n",
    "trainAcc = []\n",
    "best_acc = 0\n",
    "datetime_str = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "checkpoints_saving_path = os.path.join(checkpoint_path, datetime_str)\n",
    "os.makedirs(checkpoints_saving_path, exist_ok=True)\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch [{}/{}]'.format(epoch+1, num_epochs))\n",
    "    meanLoss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct_this_batch = (predicted == labels).sum().item()\n",
    "        correct += correct_this_batch\n",
    "        loss = criterion(outputs, labels)\n",
    "        meanLoss += loss.item()\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Step [{}/{}], Loss: {:.4f}({:.4f}), Acc: {:.3f}({:.3f})' \n",
    "                   .format(i+1, total_step, loss.item(), meanLoss / (i+1), correct_this_batch * 100 / labels.size(0), correct * 100 / total, )) \n",
    "        trainLoss.append(meanLoss/(i+1))\n",
    "        trainAcc.append(100*correct / total)\n",
    "    \n",
    "    \n",
    "    # valid the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        meanLoss = 0\n",
    "        for images, labels in valid_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            meanLoss += loss.cpu().detach().numpy()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        acc  = 100 * correct / total\n",
    "        print('Validation Accuracy : {:.4f} %, Loss : {:.4f}'.format(100 * correct / total, meanLoss/len(valid_loader)))\n",
    "        validLoss.append(meanLoss/len(valid_loader))\n",
    "        validAcc.append(acc)\n",
    "        best_acc = save_checkpoint(acc, best_acc, checkpoints_saving_path)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN - Kaggle",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
